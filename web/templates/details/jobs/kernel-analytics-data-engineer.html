{% extends 'details/jobs/base.html' %}
{% load static %}

{% block logo %}
    <img src="{% static "web/images/sponsors/kernel_analytics.png" %}" alt="Kernel Analytics">
{% endblock %}
{% block title %}DATA ENGINEER{% endblock %}
{% block description %}
    <p>
        We are looking to recruit a recently graduated or experienced computer engineer to join the technical
        team as a Junior or Senior Data Engineer. As a Data Engineer he will be the responsible to design,
        construct and install highly scalable data systems. The work will include data loading processes, full
        system process automation, API design and implementation, real time processes…
    </p>
    <p>
        The working environment will be based on Big Data technologies, with special focus on Cloud providers.
        The desired candidate should have "full-stack" profile: passionate about technology, with initiative,
        proactive, good team worker, eager to keep learning and innovating every day; someone who
        understands the importance of writing clear, descriptive, reusable code.
    </p>
    <p>
        Kernel Analytics offers the possibility to work in an innovative, young, and dynamic environment (both
        in regard to the people in the company as well as to programming languages, tools, and computer
        systems in use for the projects).
    </p>
    <p>
        REQUIRED SKILLS
    </p>
    <p>
        The candidate will be valuated according to its previous experience. The ideal candidate should have:
    </p>
    <ul>
        <li>A bachelor's degree in Computer Science or Engineering</li>
        <li>Strong programming skills, ideally in Python or a similar language</li>
        <li>Knowledge of Big Data tools (MapReduce, Hadoop, Hive, MongoDB, Cassandra…)</li>
        <li>Knowledge of SQL at proficency level</li>
        <li>Knowledge of operating systems, networks, database administration, distributed systems</li>
    </ul>
    <p>
        HIGHLY VALUED SKILLS / EXPERIENCE
    </p>
    <ul>
        <li>Knowledge of cloud systems: Amazon WS, Windows Azure</li>
        <li>Experience defining execution workflows and continuous integration</li>
        <li>Knowledge of RDBS systems (MySQL, PostgreSQL, SQL Server…) and database administration</li>
        <li>Knowledge of data ETL tools like Sqoop, Pentaho, Talend</li>
        <li>All previous experience will be considered: Github codes, websites, applications, projects, working
            experience…
        </li>
        <li>Experience with the Spark framework</li>
    </ul>
    <p>
        WHAT WE CAN OFFER
    </p>
    <ul>
        <li>Permanent contract</li>
        <li>Professional development</li>
        <li>Competitive salary</li>
        <li>Social benefits</li>
        <li>Career progression</li>
        <li>Training plan</li>
        <li>Fresh fruit and free coffee</li>
        <li>Extra free days in Christmas</li>
    </ul>
{% endblock %}

{#{% block send_request_link %}mailto:{% endblock %}#}
{% block send_request %}{% endblock %}
